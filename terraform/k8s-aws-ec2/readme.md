
# ğŸš€ Provisionamento de Cluster Kubernetes com Terraform na AWS

Este projeto contÃ©m scripts Terraform para provisionar uma infraestrutura bÃ¡sica de cluster Kubernetes na AWS, utilizando uma abordagem modular. Os recursos incluem rede (VPC, subnets, NAT, IGW), seguranÃ§a (Security Groups), e instÃ¢ncias EC2, com acesso ao cluster feito de forma segura atravÃ©s de rede privada.

## ğŸ“¦ Estrutura

O projeto utiliza um `main.tf` na raiz para orquestrar todos os mÃ³dulos Terraform. Ele Ã© responsÃ¡vel por:

- Chamar os mÃ³dulos de rede, seguranÃ§a e EC2.
- Definir as dependÃªncias e a ordem de criaÃ§Ã£o dos recursos.
- Passar variÃ¡veis entre os mÃ³dulos de forma organizada.

### Arquitetura

```bash
.
â”œâ”€â”€ main.tf
â”œâ”€â”€ vars-vpc.tf
â”œâ”€â”€ vars-subnets.tf
â”œâ”€â”€ vars-routeTable.tf
â”œâ”€â”€ vars-internetGateway.tf
â”œâ”€â”€ vars-natGateway.tf
â”œâ”€â”€ vars-securityGroups.tf
â”œâ”€â”€ vars-ec2.tf
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ vpc/
â”‚   â”œâ”€â”€ subnets/
â”‚   â”œâ”€â”€ routeTable/
â”‚   â”œâ”€â”€ internetGateway/
â”‚   â”œâ”€â”€ natGateway/
â”‚   â”œâ”€â”€ securityGroups/
â”‚   â”œâ”€â”€ ec2/
```


O cÃ³digo estÃ¡ organizado em mÃºltiplos mÃ³dulos reutilizÃ¡veis. Cada mÃ³dulo representa um componente da infraestrutura:

- `vpc/` â€“ CriaÃ§Ã£o da VPC com DNS habilitado.
- `subnets/` â€“ Subnets pÃºblicas e privadas em mÃºltiplas AZs.
- `route_tables/` â€“ Tabelas de rota para permitir comunicaÃ§Ã£o com a internet (IGW e NAT).
- `internet_gateway/` â€“ IGW vinculado Ã  VPC.
- `nat_gateway/` â€“ NAT Gateway com EIP para permitir acesso Ã  internet pelas subnets privadas.
- `security_groups/` â€“ Regras de firewall para os nÃ³s do cluster.
- `ec2/` â€“ InstÃ¢ncias EC2 (spot) para o master e os workers do cluster Kubernetes.

## ğŸŒ Topologia da Rede

```
Internet
   â”‚
[ IGW ]
   â”‚
[ Subnet PÃºblica ]
       â”‚
    [ NAT Gateway ]
       â”‚
[ Subnet Privada ]â”€â”€â”€[ EC2 Master ]
                     â””â”€â”€â”€[ EC2 Workers ]
```

- **Subnets PÃºblicas**: usadas apenas para o NAT Gateway
- **Subnets Privadas**: usadas para instÃ¢ncias de master e worker nodes
- **InstÃ¢ncias EC2 (Spot)**:
  - Master (1 instÃ¢ncia) â€” Subnet privada
  - Workers (2 instÃ¢ncias, por padrÃ£o) â€” Subnet privada

## ğŸ”§ VariÃ¡veis (Exemplos)

### VPC

```hcl
variable "vpcCidr" {
  default = "192.168.0.0/16"
}

variable "vpc_name" {
  default = "vpc_k8s_dev"
}
```

### Subnets

```hcl
locals {
  subnet_config = {
    name_prefix          = "k8s-dev"
    availability_zones   = ["us-east-1a", "us-east-1b"]
    private_subnet_cidrs = ["192.168.1.0/24", "192.168.2.0/24"]
    public_subnet_cidrs  = ["192.168.101.0/24", "192.168.102.0/24"]
  }
}
```

### Internet Gateway

```hcl
variable "igw_name" {
  default = "k8s-dev-igw"
}
```

### NAT Gateway

```hcl
variable "natgateway_name" {
  default = "k8s-dev-natgw"
}

variable "k8s_nat_eip_name" {
  default = "k8s-dev-nat-eip"
}
```

### Route Tables

```hcl
variable "cidr_rt_public" {
  default = "0.0.0.0/0"
}

variable "rt_public_name" {
  default = "rt-public"
}

variable "cidr_rt_private" {
  default = "0.0.0.0/0"
}

variable "rt_private_name" {
  default = "rt-private"
}
```

### Security Groups

```hcl
locals {
  sg_ingress_master = {
    kube_api = {
      from_port   = 6443
      to_port     = 6443
      protocol    = "tcp"
      cidr_blocks = ["0.0.0.0/0"]
    }
    kubelet = {
      from_port   = 10250
      to_port     = 10250
      protocol    = "tcp"
      cidr_blocks = ["0.0.0.0/0"]
    }
  }

  sg_ingress_nodes = {
    api_server_https = {
      from_port                = 443
      to_port                  = 443
      protocol                 = "tcp"
      source_security_group_id = null
    },
    kubelet = {
      from_port                = 10250
      to_port                  = 10250
      protocol                 = "tcp"
      source_security_group_id = null
    },
    dns_tcp = {
      from_port                = 53
      to_port                  = 53
      protocol                 = "tcp"
      source_security_group_id = null
    },
    dns_udp = {
      from_port                = 53
      to_port                  = 53
      protocol                 = "udp"
      source_security_group_id = null
    }
  }

  sg_egress_default = {
    all = {
      from_port   = 0
      to_port     = 0
      protocol    = "-1"
      cidr_blocks = ["0.0.0.0/0"]
    }
  }
}
```

### EC2

```hcl
variable "instance_type_master" {
  default = "t2.medium"
}

variable "instance_type_worker" {
  default = "t2.medium"
}

variable "worker_count" {
  default = 2
}
```

As AMIs utilizadas sÃ£o baseadas no Ubuntu 20.04 (Focal), usando as imagens oficiais da Canonical.

## â–¶ï¸ Como usar

1. Clone o repositÃ³rio:
   ```bash
   git clone https://github.com/seu-usuario/terraform-k8s-cluster.git
   cd terraform-k8s-cluster
   ```

2. Inicialize o Terraform:
   ```bash
   terraform init
   ```

3. Visualize o plano:
   ```bash
   terraform plan
   ```

4. Provisione os recursos:
   ```bash
   terraform apply
   ```

## ğŸ“ PrÃ©-requisitos

- Conta na AWS com permissÃµes adequadas
- AWS CLI configurado
- Terraform instalado (>= v1.0)

## ğŸ“š LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](./LICENSE) para mais detalhes.